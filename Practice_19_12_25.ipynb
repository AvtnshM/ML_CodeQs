{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtVx69Dm9Srl/wHXQb2GPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvtnshM/ML_CodeQs/blob/main/Practice_19_12_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LINEAR REGRESSION\n",
        "\n",
        "**What:**  \n",
        "A supervised regression algorithm that models the relationship between features and a continuous target using a straight line (or hyperplane).\n",
        "\n",
        "**Why:**  \n",
        "Simple, interpretable baseline for numeric prediction.\n",
        "\n",
        "**Where (Applications):**  \n",
        "- Housing price prediction  \n",
        "- Sales forecasting  \n",
        "- Demand estimation  \n",
        "- Stock trend approximation (baseline)\n",
        "\n",
        "**When (Ideal Conditions):**  \n",
        "- Relationship between input and output is linear  \n",
        "- Few outliers  \n",
        "- Low multicollinearity  \n",
        "\n",
        "**How (Mechanism):**  \n",
        "Minimizes sum of squared errors (OLS) to learn coefficients.  \n",
        "Uses gradient descent or closed-form solution.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "- MSE  \n",
        "- RMSE  \n",
        "- MAE  \n",
        "- R² Score  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "lkCwzZMVOFV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=1)\n",
        "\n",
        "\n",
        "model=LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "print(\"MSE: \", mse)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_test, preds, alpha = 0.5)\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.title(\"Actual vs Predicted\")\n",
        "plt.show()\n",
        "\n",
        "residuals = y_test - preds\n",
        "plt.scatter(preds, residuals, alpha = 0.5)\n",
        "plt.axhline(0, color = 'red')\n",
        "plt.xlabel(\"Predicted Prices\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residuals Plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rx_wmlzCA2co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " LOGISTIC REGRESSION\n",
        "\n",
        "**What:**  \n",
        "A supervised classification algorithm that predicts probabilities using the sigmoid function.\n",
        "\n",
        "**Why:**  \n",
        "Interpretable, fast, works well on linearly separable data.\n",
        "\n",
        "**Where:**  \n",
        "- Spam vs not spam  \n",
        "- Disease detection  \n",
        "- Fraud detection  \n",
        "- Customer churn prediction\n",
        "\n",
        "**When:**  \n",
        "- Binary or multi-class problems  \n",
        "- Need probability outputs  \n",
        "- Dataset is medium-sized and linear-ish\n",
        "\n",
        "**How:**  \n",
        "Models log-odds using sigmoid → optimized with Maximum Likelihood and gradient descent.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "- Accuracy  \n",
        "- Precision  \n",
        "- Recall  \n",
        "- F1 Score  \n",
        "- ROC–AUC  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "f9scoIjjONhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, random_state=2)\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print(\"Accuracy: \",  acc)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='d')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matric(Logistic Regression())\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8X5Yl1qlEWkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " K-MEANS CLUSTERING\n",
        "\n",
        "**What:**  \n",
        "An unsupervised clustering algorithm that groups data into K clusters by minimizing intra-cluster distance.\n",
        "\n",
        "**Why:**  \n",
        "Simple, scalable, widely used for segmentation.\n",
        "\n",
        "**Where:**  \n",
        "- Customer segmentation  \n",
        "- Image compression  \n",
        "- Market basket analysis  \n",
        "- Anomaly grouping\n",
        "\n",
        "**When:**  \n",
        "- Spherical clusters  \n",
        "- Medium-to-large datasets  \n",
        "- Unlabeled data\n",
        "\n",
        "**How:**  \n",
        "Initialize centroids → assign points → update centroids → repeat until convergence.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "- Inertia (Within-Cluster Sum of Squares)  \n",
        "- Silhouette Score  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PlgjFXaYOVj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_iris()\n",
        "\n",
        "X = data.data\n",
        "\n",
        "kmeans = KMeans(n_clusters = 3, random_state = 1)\n",
        "kmeans.fit(X)\n",
        "\n",
        "labels = kmeans.labels_\n",
        "\n",
        "plt.scatter(X[:, 2], X[:, 3], c =labels)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DdnqPtFsHfr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " SUPPORT VECTOR MACHINE (SVM)\n",
        "\n",
        "**What:**  \n",
        "A supervised algorithm that finds the best separating hyperplane with maximum margin between classes.\n",
        "\n",
        "**Why:**  \n",
        "Effective for small/medium datasets & high-dimensional spaces.\n",
        "\n",
        "**Where:**  \n",
        "- Text classification  \n",
        "- Image classification  \n",
        "- Bioinformatics  \n",
        "- Handwritten digit recognition\n",
        "\n",
        "**When:**  \n",
        "- Datasets with clear class margins  \n",
        "- Small or medium-sized datasets  \n",
        "- High dimensionality (e.g., text)  \n",
        "\n",
        "**How:**  \n",
        "Maximizes margin using hinge loss.  \n",
        "Uses kernel trick for non-linear separation.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "- Accuracy  \n",
        "- Precision  \n",
        "- Recall  \n",
        "- F1 Score  \n",
        "- ROC–AUC  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "F0_de33nPa2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 0.8, random_state = 1)\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "print(\"Accuracy :\", accuracy_score(y_test, preds))\n"
      ],
      "metadata": {
        "id": "QnlA3ObDQaG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " DECISION TREE\n",
        "\n",
        "**What:**  \n",
        "A supervised model that splits data based on feature values to make decisions in a tree-like structure.\n",
        "\n",
        "**Why:**  \n",
        "Interpretable, handles non-linearity, no scaling needed.\n",
        "\n",
        "**Where:**  \n",
        "- Credit scoring  \n",
        "- Risk analysis  \n",
        "- Medical diagnosis  \n",
        "- Loan approval\n",
        "\n",
        "**When:**  \n",
        "- Mixed data types (categorical + numeric)  \n",
        "- Interpretability required  \n",
        "- Non-linear decision boundaries\n",
        "\n",
        "**How:**  \n",
        "Splits using Gini impurity or entropy → maximize information gain.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "- Accuracy  \n",
        "- Precision/Recall/F1  \n",
        "- MAE/MSE (regression trees)  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8Dbe_B1ZPhOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets  import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy :\", accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "id": "w10HJFTIS9nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " RANDOM FOREST\n",
        "\n",
        "**What:**  \n",
        "Ensemble of decision trees trained on bootstrapped datasets with feature randomness.\n",
        "\n",
        "**Why:**  \n",
        "Reduces overfitting, improves accuracy vs a single tree.\n",
        "\n",
        "**Where:**  \n",
        "- Credit scoring  \n",
        "- HR attrition  \n",
        "- Sales prediction  \n",
        "- Medical diagnosis  \n",
        "- Tabular Kaggle competitions\n",
        "\n",
        "**When:**  \n",
        "- Need robust general-purpose model  \n",
        "- Avoid overfitting of single trees  \n",
        "- Large feature space  \n",
        "\n",
        "**How:**  \n",
        "Bagging (data sampling) + random features → aggregate predictions (majority vote/mean).\n",
        "\n",
        "**Validation Metrics:**  \n",
        "- Accuracy (classification)  \n",
        "- Precision/Recall/F1  \n",
        "- ROC–AUC  \n",
        "- MSE/RMSE (regression)"
      ],
      "metadata": {
        "id": "rBd9PSH4Po8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, random_state = 23)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "id": "K9QHwOSnVCt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbors (KNN)\n",
        "\n",
        "**What:**  \n",
        "An instance-based ML algorithm that predicts by using the closest K points.\n",
        "\n",
        "**Why:**  \n",
        "No training time, simple, handles non-linear decision boundaries.\n",
        "\n",
        "**Where:**  \n",
        "Recommendation, pattern recognition, medical baseline, image classification.\n",
        "\n",
        "**When:**  \n",
        "Small datasets, local patterns matter, non-parametric spaces.\n",
        "\n",
        "**How:**  \n",
        "Calculate distance → pick K neighbors → voting (classification) or averaging (regression).\n",
        "\n",
        "**Validation Metrics:**  \n",
        "Accuracy, Precision/Recall/F1, MSE (regression)"
      ],
      "metadata": {
        "id": "ijDgbdKlW7e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y = True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(X_train, y_train)\n",
        "print(\"Accuracy: \", accuracy_score(y_test, knn.predict(X_test)))\n",
        "\n"
      ],
      "metadata": {
        "id": "aXXSIRgIWGTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3025ec91-07b9-4ef3-b89f-28b6d86fb8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Naive Bayes (NB)\n",
        "\n",
        "**What:**  \n",
        "A probabilistic classifier based on Bayes theorem assuming independent features.\n",
        "\n",
        "**Why:**  \n",
        "Extremely fast, great on text & sparse data.\n",
        "\n",
        "**Where:**  \n",
        "Spam detection, sentiment analysis, document tagging.\n",
        "\n",
        "**When:**  \n",
        "High dimensional text, low compute, limited data.\n",
        "\n",
        "**How:**  \n",
        "Computes posterior probability: P(class|features) using independence.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "Accuracy, Precision, Recall, F1, ROC–AUC\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "5gIyC6pgYJ2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nb = GaussianNB()\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy: ', accuracy_score(y_test, nb.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U95JSxLdYTb_",
        "outputId": "74ea382e-bddc-4c3d-b1db-0a507fe30e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Principal Component Analysis (PCA)\n",
        "\n",
        "**What:**  \n",
        "Dimensionality reduction by projecting data onto max variance directions.\n",
        "\n",
        "**Why:**  \n",
        "Reduce redundancy, compression, visualization, speed-up ML.\n",
        "\n",
        "**Where:**  \n",
        "Preprocessing, compression, noise reduction, 2D/3D visualization.\n",
        "\n",
        "**When:**  \n",
        "High dimensional data, multicollinearity, visualization required.\n",
        "\n",
        "**How:**  \n",
        "Covariance matrix → eigen decomposition → keep top k components.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "Explained variance ratio, reconstruction error (optional)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "54F9uO7QYT_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X= data.data\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "print(\"PCA Variance Ratio: \", pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsx4SsHQYZaf",
        "outputId": "a30a487c-6bd5-442f-e4b9-344846c60db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA Variance Ratio:  [0.92461872 0.05306648]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Family (XGB / LightGBM / CatBoost)\n",
        "\n",
        "**What:**  \n",
        "Ensemble method where new trees correct previous errors sequentially.\n",
        "\n",
        "**Why:**  \n",
        "State-of-the-art performance on tabular data.\n",
        "\n",
        "**Where:**  \n",
        "Kaggle, credit scoring, forecasting, churn modeling.\n",
        "\n",
        "**When:**  \n",
        "Large data, complex relationships, need max accuracy.\n",
        "\n",
        "**How:**  \n",
        "Gradient descent on loss + boosted weak learners (trees).\n",
        "\n",
        "**Validation Metrics:**  \n",
        "Accuracy/F1 (classification), ROC–AUC, RMSE/MAE (regression)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RTqaFqCoYaJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "xgb = XGBClassifier(eval_metric = 'logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy: ', accuracy_score(y_test, xgb.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQEyb00zYgjR",
        "outputId": "0f92c981-06ed-4d8f-ed8e-bea4a3f37ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Artificial Neural Network (ANN)\n",
        "\n",
        "**What:**  \n",
        "Network of neurons that learns hierarchical patterns through layers.\n",
        "\n",
        "**Why:**  \n",
        "Captures complex non-linear relationships.\n",
        "\n",
        "**Where:**  \n",
        "Images, NLP, tabular prediction, time series.\n",
        "\n",
        "**When:**  \n",
        "Large datasets, interactions unknown, non-linear spaces.\n",
        "\n",
        "**How:**  \n",
        "Forward pass → loss → backpropagation updates weights.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "Accuracy, Cross-Entropy Loss, MSE (regression)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_gsjbLF8YhZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "y_cat = to_categorical(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, train_size = 0.8, random_state = 1)\n",
        "\n",
        "ann = Sequential([\n",
        "    Dense(8, activation = 'relu', input_shape = (4, )),\n",
        "    Dense(3, activation = 'softmax')\n",
        "])\n",
        "\n",
        "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics =['accuracy'])\n",
        "ann.fit(X_train, y_train, epochs =10, verbose = 0)\n",
        "\n",
        "loss, acc = ann.evaluate(X_test, y_test, verbose = 0)\n",
        "\n",
        "print(\"Accuracy: \", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfYyco7NYoHP",
        "outputId": "80b63d64-051a-4093-a497-6d81e3b8b38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.36666667461395264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Gradient Descent (GD)\n",
        "\n",
        "**What:**  \n",
        "Optimization algorithm used to minimize cost functions.\n",
        "\n",
        "**Why:**  \n",
        "Works for large models where closed-form solution is impossible.\n",
        "\n",
        "**Where:**  \n",
        "Logistic/Linear Regression, SVM, Neural Networks.\n",
        "\n",
        "**When:**  \n",
        "Large parameters, iterative optimization needed.\n",
        "\n",
        "**How:**  \n",
        "Compute gradient of loss → move in negative gradient direction.\n",
        "\n",
        "**Validation Metrics:**  \n",
        "Not a model → observe decreasing loss & convergence."
      ],
      "metadata": {
        "id": "S5v7C8FkYoiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.array([1,2,3,4], dtype =float)\n",
        "y = np.array([2,4,6,8], dtype =float)\n",
        "\n",
        "w = 0\n",
        "lr = 0.01\n",
        "\n",
        "for _ in range(100):\n",
        "  pred = w * X\n",
        "  grad = np.mean((pred - y)   * X)\n",
        "  w -= lr * grad\n",
        "\n",
        "print(\"GD Learned Weight: \", w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0xd2_oHYuCf",
        "outputId": "c9a71e34-b4eb-4c6b-8fe2-00d39b42360d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GD Learned Weight:  1.9991773724130237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tM1VZWpNk2Mj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}